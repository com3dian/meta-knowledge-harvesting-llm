Entities: defaultdict(<class 'list'>, {'Text Representation Models': [{'entity_name': 'Text Representation Models', 'entity_type': 'Software or Computational Method', 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Societal Biases': [{'entity_name': 'Societal Biases', 'entity_type': 'Health or Disease Concept', 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Pretrained Language Models': [{'entity_name': 'Pretrained Language Models', 'entity_type': 'Software or Computational Method', 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Bias Measurement': [{'entity_name': 'Bias Measurement', 'entity_type': 'Scientific Method', 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Bias Mitigation': [{'entity_name': 'Bias Mitigation', 'entity_type': 'Scientific Method', 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Conversational Language Models': [{'entity_name': 'Conversational Language Models', 'entity_type': 'Software or Computational Method', 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Debiasing Methods': [{'entity_name': 'Debiasing Methods', 'entity_type': 'Software or Computational Method', 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'REDDITBIAS': [{'entity_name': 'REDDITBIAS', 'entity_type': 'Software or Computational Method', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Gender': [{'entity_name': 'Gender', 'entity_type': 'Demographic Group', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Race': [{'entity_name': 'Race', 'entity_type': 'Demographic Group', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Religion': [{'entity_name': 'Religion', 'entity_type': 'Demographic Group', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Queerness': [{'entity_name': 'Queerness', 'entity_type': 'Demographic Group', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Evaluation Framework': [{'entity_name': 'Evaluation Framework', 'entity_type': 'Scientific Method', 'description': 'Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'DialoGPT Model': [{'entity_name': 'DialoGPT Model', 'entity_type': 'Software or Computational Method', 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Religious Groups': [{'entity_name': 'Religious Groups', 'entity_type': 'Demographic Group', 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Ethical Issues': [{'entity_name': 'Ethical Issues', 'entity_type': 'Health or Disease Concept', 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Bias Amplification': [{'entity_name': 'Bias Amplification', 'entity_type': 'Health or Disease Concept', 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Bias Measurements and Mitigation Resources and Methods': [{'entity_name': 'Bias Measurements and Mitigation Resources and Methods', 'entity_type': 'Scientific Method', 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Conversational Response Generation': [{'entity_name': 'Conversational Response Generation', 'entity_type': 'Software or Computational Method', 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Reddit': [{'entity_name': 'Reddit', 'entity_type': 'Institution or Organization', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'DialoGPT': [{'entity_name': 'DialoGPT', 'entity_type': 'Software or Computational Method', 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Pretraining Data': [{'entity_name': 'Pretraining Data', 'entity_type': 'Software or Computational Method', 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Dialog Tasks': [{'entity_name': 'Dialog Tasks', 'entity_type': 'Software or Computational Method', 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Human Conversations From Reddit': [{'entity_name': 'Human Conversations From Reddit', 'entity_type': 'Software or Computational Method', 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Model Capability': [{'entity_name': 'Model Capability', 'entity_type': 'Scientific Method', 'description': 'Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], 'Downstream Task Performance': [{'entity_name': 'Downstream Task Performance', 'entity_type': 'Measurement or Quantity', 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}]})
Relationships: defaultdict(<class 'list'>, {('Societal Biases', 'Text Representation Models'): [{'src_id': 'Text Representation Models', 'tgt_id': 'Societal Biases', 'weight': 9.0, 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'keywords': 'causation, inherent characteristic', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Ethical Issues', 'Societal Biases'): [{'src_id': 'Societal Biases', 'tgt_id': 'Ethical Issues', 'weight': 9.0, 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'keywords': 'consequence, impact', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Amplification', 'Societal Biases'): [{'src_id': 'Societal Biases', 'tgt_id': 'Bias Amplification', 'weight': 9.0, 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'keywords': 'consequence, exacerbation', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Measurement', 'Pretrained Language Models'): [{'src_id': 'Bias Measurement', 'tgt_id': 'Pretrained Language Models', 'weight': 8.0, 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'keywords': 'research focus, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Mitigation', 'Pretrained Language Models'): [{'src_id': 'Bias Mitigation', 'tgt_id': 'Pretrained Language Models', 'weight': 8.0, 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'keywords': 'research focus, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Measurement', 'Conversational Language Models'): [{'src_id': 'Bias Measurement', 'tgt_id': 'Conversational Language Models', 'weight': 7.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'research gap, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Mitigation', 'Conversational Language Models'): [{'src_id': 'Bias Mitigation', 'tgt_id': 'Conversational Language Models', 'weight': 7.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'research gap, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Measurement', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Bias Measurement', 'weight': 9.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'resource, enablement', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Mitigation', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Bias Mitigation', 'weight': 9.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'resource, enablement', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Gender', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Gender', 'weight': 8.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'scope, dimension', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('REDDITBIAS', 'Race'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Race', 'weight': 8.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'scope, dimension', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('REDDITBIAS', 'Religion'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Religion', 'weight': 8.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'scope, dimension', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Queerness', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Queerness', 'weight': 8.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'scope, dimension', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Evaluation Framework', 'REDDITBIAS'): [{'src_id': 'Evaluation Framework', 'tgt_id': 'REDDITBIAS', 'weight': 9.0, 'description': 'Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing.', 'keywords': 'utilization, assessment', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('DialoGPT Model', 'Evaluation Framework'): [{'src_id': 'Evaluation Framework', 'tgt_id': 'DialoGPT Model', 'weight': 9.0, 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'keywords': 'benchmarking, assessment', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('DialoGPT Model', 'Religious Groups'): [{'src_id': 'DialoGPT Model', 'tgt_id': 'Religious Groups', 'weight': 9.0, 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'keywords': 'bias, characteristic', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Debiasing Methods', 'DialoGPT Model'): [{'src_id': 'Debiasing Methods', 'tgt_id': 'DialoGPT Model', 'weight': 8.0, 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'keywords': 'application, intervention', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Debiasing Methods', 'Religious Groups'): [{'src_id': 'Debiasing Methods', 'tgt_id': 'Religious Groups', 'weight': 9.0, 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'keywords': 'mitigation, removal', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Pretrained Language Models', 'Societal Biases'): [{'src_id': 'Pretrained Language Models', 'tgt_id': 'Societal Biases', 'weight': 8.0, 'description': 'Recent work has predominantly focused on measuring and mitigating bias in pretrained language models.', 'keywords': 'bias mitigation, research focus', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Measurements and Mitigation Resources and Methods', 'Conversational Language Models'): [{'src_id': 'Conversational Language Models', 'tgt_id': 'Bias Measurements and Mitigation Resources and Methods', 'weight': 7.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'research gap, resource scarcity', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Conversational Language Models', 'Conversational Response Generation'): [{'src_id': 'Conversational Language Models', 'tgt_id': 'Conversational Response Generation', 'weight': 8.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'application, task performance', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('REDDITBIAS', 'Reddit'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Reddit', 'weight': 10.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'data source, dataset creation', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Bias Measurements and Mitigation Resources and Methods', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Bias Measurements and Mitigation Resources and Methods', 'weight': 9.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'resource for methods, bias analysis', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('DialoGPT', 'Evaluation Framework'): [{'src_id': 'Evaluation Framework', 'tgt_id': 'DialoGPT', 'weight': 9.0, 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'keywords': 'model benchmarking, evaluation tool', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Debiasing Methods', 'DialoGPT'): [{'src_id': 'DialoGPT', 'tgt_id': 'Debiasing Methods', 'weight': 9.0, 'description': 'We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods.', 'keywords': 'model treatment, bias removal', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('DialoGPT', 'Religious Groups'): [{'src_id': 'DialoGPT', 'tgt_id': 'Religious Groups', 'weight': 10.0, 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'keywords': 'model bias, demographic impact', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Pretraining Data', 'Text Representation Models'): [{'src_id': 'Text Representation Models', 'tgt_id': 'Pretraining Data', 'weight': 8.0, 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'keywords': 'dependency, source', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Pretraining Data', 'Societal Biases'): [{'src_id': 'Pretraining Data', 'tgt_id': 'Societal Biases', 'weight': 9.0, 'description': 'Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification.', 'keywords': 'source of bias, causation', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Debiasing Methods', 'Dialog Tasks'): [{'src_id': 'Debiasing Methods', 'tgt_id': 'Dialog Tasks', 'weight': 8.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'impact, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Conversational Response Generation', 'Debiasing Methods'): [{'src_id': 'Debiasing Methods', 'tgt_id': 'Conversational Response Generation', 'weight': 8.0, 'description': 'Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation.', 'keywords': 'impact, application', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Human Conversations From Reddit', 'REDDITBIAS'): [{'src_id': 'REDDITBIAS', 'tgt_id': 'Human Conversations From Reddit', 'weight': 9.0, 'description': 'In this work, we present REDDITBIAS, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness.', 'keywords': 'source, grounding', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Evaluation Framework', 'Model Capability'): [{'src_id': 'Evaluation Framework', 'tgt_id': 'Model Capability', 'weight': 9.0, 'description': 'Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing.', 'keywords': 'assessment, scope', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Dialog Tasks', 'Evaluation Framework'): [{'src_id': 'Evaluation Framework', 'tgt_id': 'Dialog Tasks', 'weight': 9.0, 'description': 'Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed REDDITBIAS resource, and 2) evaluates model capability in dialog tasks after model debiasing.', 'keywords': 'assessment, scope', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('Debiasing Methods', 'Downstream Task Performance'): [{'src_id': 'Debiasing Methods', 'tgt_id': 'Downstream Task Performance', 'weight': 9.0, 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'keywords': 'impact, preservation', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}], ('DialoGPT Model', 'Downstream Task Performance'): [{'src_id': 'DialoGPT Model', 'tgt_id': 'Downstream Task Performance', 'weight': 8.0, 'description': 'Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance.', 'keywords': 'performance, outcome', 'source_id': 'chunk-19ed5b856fe34613cd8be703cd479664', 'file_path': 'example.txt'}]})
