Entities: defaultdict(<class 'list'>, {'Machine-Learning-Based Approaches': [{'entity_name': 'Machine-Learning-Based Approaches', 'entity_type': 'Software or Computational Method', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Clinical Entities': [{'entity_name': 'Clinical Entities', 'entity_type': 'Health or Disease Concept', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language. The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge': [{'entity_name': '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'entity_type': 'Scientific Method', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge. Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|': [{'entity_name': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|', 'entity_type': 'Institution or Organization', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge. Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Natural-Language-Processing (NLP)"|': [{'entity_name': 'Natural-Language-Processing (NLP)"|', 'entity_type': 'Software or Computational Method', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge. Semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Machine-Learning-Based Named Entity Recognition System': [{'entity_name': 'Machine-Learning-Based Named Entity Recognition System', 'entity_type': 'Software or Computational Method', 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Systematic Evaluation': [{'entity_name': 'Systematic Evaluation', 'entity_type': 'Scientific Method', 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes. Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Training Corpus': [{'entity_name': 'Training Corpus', 'entity_type': 'Scientific Method', 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '349 Annotated Notes': [{'entity_name': '349 Annotated Notes', 'entity_type': 'Measurement or Quantity', 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Novel Hybrid Clinical Entity Extraction System': [{'entity_name': 'Novel Hybrid Clinical Entity Extraction System', 'entity_type': 'Software or Computational Method', 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module. The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Heuristic Rule-Based Modules': [{'entity_name': 'Heuristic Rule-Based Modules', 'entity_type': 'Software or Computational Method', 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'ML-Base Named Entity Recognition Module': [{'entity_name': 'ML-Base Named Entity Recognition Module', 'entity_type': 'Software or Computational Method', 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Concept Extraction Tasks': [{'entity_name': 'Concept Extraction Tasks', 'entity_type': 'Scientific Method', 'description': "The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes. The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Assertion Classification Tasks': [{'entity_name': 'Assertion Classification Tasks', 'entity_type': 'Scientific Method', 'description': "The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes. The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Test Data Set': [{'entity_name': 'Test Data Set', 'entity_type': 'Scientific Method', 'description': "The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes. The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '477 Annotated Notes': [{'entity_name': '477 Annotated Notes', 'entity_type': 'Measurement or Quantity', 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes. The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Standard Measures': [{'entity_name': 'Standard Measures', 'entity_type': 'Scientific Method', 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Precision': [{'entity_name': 'Precision', 'entity_type': 'Scientific Method', 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Recall': [{'entity_name': 'Recall', 'entity_type': 'Scientific Method', 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'F-Measure': [{'entity_name': 'F-Measure', 'entity_type': 'Scientific Method', 'description': "Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers. The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Evaluation Script': [{'entity_name': 'Evaluation Script', 'entity_type': 'Software or Computational Method', 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Primary Metric': [{'entity_name': 'Primary Metric', 'entity_type': 'Scientific Method', 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Conditional Random Fields': [{'entity_name': 'Conditional Random Fields', 'entity_type': 'Software or Computational Method', 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Support Vector Machines': [{'entity_name': 'Support Vector Machines', 'entity_type': 'Software or Computational Method', 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Semantic Information': [{'entity_name': 'Semantic Information', 'entity_type': 'Scientific Method', 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '0.8391': [{'entity_name': '0.8391', 'entity_type': 'Measurement or Quantity', 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '0.9313': [{'entity_name': '0.9313', 'entity_type': 'Measurement or Quantity', 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], '2010': [{'entity_name': '2010', 'entity_type': 'Time Expression', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Hospital Discharge Summaries': [{'entity_name': 'Hospital Discharge Summaries', 'entity_type': 'Health or Disease Concept', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)': [{'entity_name': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)', 'entity_type': 'Institution or Organization', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Natural-Language-Processing Challenge': [{'entity_name': 'Natural-Language-Processing Challenge', 'entity_type': 'Scientific Method', 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'ML Algorithms': [{'entity_name': 'ML Algorithms', 'entity_type': 'Software or Computational Method', 'description': 'The authors implemented a machine-learningbased named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Training Corpus of 349 Annotated Notes': [{'entity_name': 'Training Corpus of 349 Annotated Notes', 'entity_type': 'Measurement or Quantity', 'description': 'The authors implemented a machine-learningbased named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Concept Extraction Task': [{'entity_name': 'Concept Extraction Task', 'entity_type': 'Scientific Method', 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Assertion Classification Task': [{'entity_name': 'Assertion Classification Task', 'entity_type': 'Scientific Method', 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Test Data Set with 477 Annotated Notes': [{'entity_name': 'Test Data Set with 477 Annotated Notes', 'entity_type': 'Measurement or Quantity', 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Precision, Recall, and F-Measure': [{'entity_name': 'Precision, Recall, and F-Measure', 'entity_type': 'Measurement or Quantity', 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Semantic Information from Natural-Language-Processing Systems': [{'entity_name': 'Semantic Information from Natural-Language-Processing Systems', 'entity_type': 'Software or Computational Method', 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Overall F-score of 0.8391': [{'entity_name': 'Overall F-score of 0.8391', 'entity_type': 'Measurement or Quantity', 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Overall F-score of 0.9313': [{'entity_name': 'Overall F-score of 0.9313', 'entity_type': 'Measurement or Quantity', 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Medical Problems': [{'entity_name': 'Medical Problems', 'entity_type': 'Health or Disease Concept', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Tests': [{'entity_name': 'Tests', 'entity_type': 'Health or Disease Concept', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Treatments': [{'entity_name': 'Treatments', 'entity_type': 'Health or Disease Concept', 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Clinical Text': [{'entity_name': 'Clinical Text', 'entity_type': 'Scientific Method', 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], 'Assertions': [{'entity_name': 'Assertions', 'entity_type': 'Health or Disease Concept', 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}]})
Relationships: defaultdict(<class 'list'>, {('Clinical Entities', 'Machine-Learning-Based Approaches'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Clinical Entities', 'weight': 9.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'entity extraction, application', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Approaches', 'Machine-Learning-Based Named Entity Recognition System'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Machine-Learning-Based Named Entity Recognition System', 'weight': 9.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language. The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.", 'keywords': 'implementation, specific instance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|'): [{'src_id': '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'tgt_id': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|', 'weight': 8.0, 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge. Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'organization, event host', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'Natural-Language-Processing (NLP)"|'): [{'src_id': '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'tgt_id': 'Natural-Language-Processing (NLP)"|', 'weight': 8.0, 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'keywords': 'focus, domain', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('2010', '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge'): [{'src_id': '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'tgt_id': '2010', 'weight': 9.0, 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'keywords': 'event timing, historical context', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Conditional Random Fields', 'Natural-Language-Processing (NLP)"|'): [{'src_id': 'Natural-Language-Processing (NLP)"|', 'tgt_id': 'Conditional Random Fields', 'weight': 7.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'performance improvement, feature source', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Natural-Language-Processing (NLP)"|', 'Support Vector Machines'): [{'src_id': 'Natural-Language-Processing (NLP)"|', 'tgt_id': 'Support Vector Machines', 'weight': 7.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'performance improvement, feature source', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Natural-Language-Processing (NLP)"|', 'Semantic Information'): [{'src_id': 'Natural-Language-Processing (NLP)"|', 'tgt_id': 'Semantic Information', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'data source, feature generation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Named Entity Recognition System', 'Training Corpus'): [{'src_id': 'Machine-Learning-Based Named Entity Recognition System', 'tgt_id': 'Training Corpus', 'weight': 8.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'data source, evaluation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Named Entity Recognition System', 'Natural-Language-Processing (NLP)"|'): [{'src_id': 'Machine-Learning-Based Named Entity Recognition System', 'tgt_id': 'Natural-Language-Processing (NLP)"|', 'weight': 8.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'system type, domain application', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}, {'src_id': 'Natural-Language-Processing (NLP)"|', 'tgt_id': 'Machine-Learning-Based Named Entity Recognition System', 'weight': 8.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'domain, application', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Systematic Evaluation', 'Training Corpus'): [{'src_id': 'Systematic Evaluation', 'tgt_id': 'Training Corpus', 'weight': 9.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'data source, methodology', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Conditional Random Fields', 'Systematic Evaluation'): [{'src_id': 'Systematic Evaluation', 'tgt_id': 'Conditional Random Fields', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'evaluation result, algorithm performance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Support Vector Machines', 'Systematic Evaluation'): [{'src_id': 'Systematic Evaluation', 'tgt_id': 'Support Vector Machines', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'evaluation result, algorithm performance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('349 Annotated Notes', 'Training Corpus'): [{'src_id': 'Training Corpus', 'tgt_id': '349 Annotated Notes', 'weight': 9.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'composition, quantity', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Heuristic Rule-Based Modules', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Heuristic Rule-Based Modules', 'weight': 9.0, 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module.', 'keywords': 'integration, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('ML-Base Named Entity Recognition Module', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'ML-Base Named Entity Recognition Module', 'weight': 9.0, 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module.', 'keywords': 'integration, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Concept Extraction Tasks', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Concept Extraction Tasks', 'weight': 8.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'application, task', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertion Classification Tasks', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Assertion Classification Tasks', 'weight': 8.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'application, task', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Novel Hybrid Clinical Entity Extraction System', 'Test Data Set'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Test Data Set', 'weight': 9.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'evaluation, data source', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Natural-Language-Processing (NLP)"|', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Natural-Language-Processing (NLP)"|', 'weight': 8.0, 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module. The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'system type, domain application', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('F-Measure', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'F-Measure', 'weight': 9.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'performance metric, system evaluation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Named Entity Recognition System', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Machine-Learning-Based Named Entity Recognition System', 'weight': 9.0, 'description': 'Based on the results from training data, the authors developed a novel hybrid clinical entity extraction system, which integrated heuristic rule-based modules with the ML-base named entity recognition module.', 'keywords': 'integration, core component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('477 Annotated Notes', 'Test Data Set'): [{'src_id': 'Test Data Set', 'tgt_id': '477 Annotated Notes', 'weight': 9.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'composition, quantity', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Precision', 'Standard Measures'): [{'src_id': 'Standard Measures', 'tgt_id': 'Precision', 'weight': 9.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'type of, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Recall', 'Standard Measures'): [{'src_id': 'Standard Measures', 'tgt_id': 'Recall', 'weight': 9.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'type of, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('F-Measure', 'Standard Measures'): [{'src_id': 'Standard Measures', 'tgt_id': 'F-Measure', 'weight': 9.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'type of, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Evaluation Script', 'F-Measure'): [{'src_id': 'F-Measure', 'tgt_id': 'Evaluation Script', 'weight': 8.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'calculation method, tool use', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('0.8391', 'F-Measure'): [{'src_id': 'F-Measure', 'tgt_id': '0.8391', 'weight': 9.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'measurement, result', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('0.9313', 'F-Measure'): [{'src_id': 'F-Measure', 'tgt_id': '0.9313', 'weight': 9.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'measurement, result', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Conditional Random Fields', 'Support Vector Machines'): [{'src_id': 'Conditional Random Fields', 'tgt_id': 'Support Vector Machines', 'weight': 7.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'performance comparison, algorithm comparison', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Conditional Random Fields', 'Semantic Information'): [{'src_id': 'Semantic Information', 'tgt_id': 'Conditional Random Fields', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'feature impact, performance enhancement', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Semantic Information', 'Support Vector Machines'): [{'src_id': 'Semantic Information', 'tgt_id': 'Support Vector Machines', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'feature impact, performance enhancement', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Primary Metric'): [{'src_id': 'Primary Metric', 'tgt_id': 'Clinical Entities', 'weight': 9.0, 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'keywords': 'evaluation criteria, measurement target', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('0.8391', 'Concept Extraction Tasks'): [{'src_id': 'Concept Extraction Tasks', 'tgt_id': '0.8391', 'weight': 9.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'task performance, result', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('0.9313', 'Assertion Classification Tasks'): [{'src_id': 'Assertion Classification Tasks', 'tgt_id': '0.9313', 'weight': 9.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'task performance, result', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Hospital Discharge Summaries', 'Machine-Learning-Based Approaches'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Hospital Discharge Summaries', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'data source, extraction target', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Hospital Discharge Summaries'): [{'src_id': 'Clinical Entities', 'tgt_id': 'Hospital Discharge Summaries', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'content, data origin', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)', 'Natural-Language-Processing Challenge'): [{'src_id': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)', 'tgt_id': 'Natural-Language-Processing Challenge', 'weight': 9.0, 'description': 'This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.', 'keywords': 'organization, event sponsorship', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Machine-Learning-Based Named Entity Recognition System'): [{'src_id': 'Machine-Learning-Based Named Entity Recognition System', 'tgt_id': 'Clinical Entities', 'weight': 8.0, 'description': 'The authors implemented a machine-learningbased named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'system implementation, entity recognition', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Named Entity Recognition System', 'Training Corpus of 349 Annotated Notes'): [{'src_id': 'Training Corpus of 349 Annotated Notes', 'tgt_id': 'Machine-Learning-Based Named Entity Recognition System', 'weight': 8.0, 'description': 'The authors implemented a machine-learningbased named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'data source, system training', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Concept Extraction Task', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Concept Extraction Task', 'weight': 9.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'system application, task performance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertion Classification Task', 'Novel Hybrid Clinical Entity Extraction System'): [{'src_id': 'Novel Hybrid Clinical Entity Extraction System', 'tgt_id': 'Assertion Classification Task', 'weight': 9.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'system application, task performance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Novel Hybrid Clinical Entity Extraction System', 'Test Data Set with 477 Annotated Notes'): [{'src_id': 'Test Data Set with 477 Annotated Notes', 'tgt_id': 'Novel Hybrid Clinical Entity Extraction System', 'weight': 9.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'data source, system evaluation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Evaluation Script', 'Precision, Recall, and F-Measure'): [{'src_id': 'Precision, Recall, and F-Measure', 'tgt_id': 'Evaluation Script', 'weight': 9.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'measurement calculation, evaluation tool', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)', 'Evaluation Script'): [{'src_id': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)', 'tgt_id': 'Evaluation Script', 'weight': 8.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'organization, tool provision', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Named Entity Recognition System', 'Semantic Information from Natural-Language-Processing Systems'): [{'src_id': 'Semantic Information from Natural-Language-Processing Systems', 'tgt_id': 'Machine-Learning-Based Named Entity Recognition System', 'weight': 7.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'performance improvement, feature contribution', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Concept Extraction Task', 'Overall F-score of 0.8391'): [{'src_id': 'Concept Extraction Task', 'tgt_id': 'Overall F-score of 0.8391', 'weight': 10.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'task result, performance metric', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertion Classification Task', 'Overall F-score of 0.9313'): [{'src_id': 'Assertion Classification Task', 'tgt_id': 'Overall F-score of 0.9313', 'weight': 10.0, 'description': "The authors' hybrid entity extraction system achieved a maximumoverall F-score of 0.8391 for concept extraction (ranked second) and 0.9313 for assertion classification (ranked fourth, but not statistically different than the first three systems) on the test data set in the challenge.", 'keywords': 'task result, performance metric', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Approaches', 'Medical Problems'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Medical Problems', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'extraction, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Approaches', 'Tests'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Tests', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'extraction, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Approaches', 'Treatments'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Treatments', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'extraction, component', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Machine-Learning-Based Approaches', 'Natural-Language-Processing (NLP)"|'): [{'src_id': 'Machine-Learning-Based Approaches', 'tgt_id': 'Natural-Language-Processing (NLP)"|', 'weight': 9.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language. This project was part of the 2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) natural-language-processing challenge.", 'keywords': 'application domain, methodology', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Medical Problems'): [{'src_id': 'Clinical Entities', 'tgt_id': 'Medical Problems', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'component, type', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Tests'): [{'src_id': 'Clinical Entities', 'tgt_id': 'Tests', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'component, type', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Treatments'): [{'src_id': 'Clinical Entities', 'tgt_id': 'Treatments', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'component, type', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'Evaluation Script'): [{'src_id': '2010 Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA) Natural-Language-Processing Challenge', 'tgt_id': 'Evaluation Script', 'weight': 8.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'tool provision, challenge context', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|', 'Evaluation Script'): [{'src_id': 'Center of Informatics for Integrating Biology and the Bedside/Veterans Affairs (VA)"|', 'tgt_id': 'Evaluation Script', 'weight': 8.0, 'description': 'Standard measures including precision, recall, and F-measure were calculated using the evaluation script provided by the Center of Informatics for Integrating Biology and the Bedside/VA challenge organizers.', 'keywords': 'tool provision, organizational role', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('ML Algorithms', 'Natural-Language-Processing (NLP)"|'): [{'src_id': 'Natural-Language-Processing (NLP)"|', 'tgt_id': 'ML Algorithms', 'weight': 7.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'application domain, technique', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Text', 'Machine-Learning-Based Named Entity Recognition System'): [{'src_id': 'Machine-Learning-Based Named Entity Recognition System', 'tgt_id': 'Clinical Text', 'weight': 8.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'application, input', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('ML Algorithms', 'Machine-Learning-Based Named Entity Recognition System'): [{'src_id': 'Machine-Learning-Based Named Entity Recognition System', 'tgt_id': 'ML Algorithms', 'weight': 8.0, 'description': 'The authors implemented a machine-learning-based named entity recognition system for clinical text and systematically evaluated the contributions of different types of features and ML algorithms, using a training corpus of 349 annotated notes.', 'keywords': 'component, underlying method', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Conditional Random Fields', 'ML Algorithms'): [{'src_id': 'ML Algorithms', 'tgt_id': 'Conditional Random Fields', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'type of, instance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('ML Algorithms', 'Support Vector Machines'): [{'src_id': 'ML Algorithms', 'tgt_id': 'Support Vector Machines', 'weight': 8.0, 'description': 'Systematic evaluation on the training set showed that Conditional Random Fields outperformed Support Vector Machines, and semantic information from existing natural-language-processing systems largely improved performance, although contributions from different types of features varied.', 'keywords': 'type of, instance', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Test Data Set'): [{'src_id': 'Test Data Set', 'tgt_id': 'Clinical Entities', 'weight': 8.0, 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'keywords': 'evaluation target, data scope', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertions', 'Test Data Set'): [{'src_id': 'Test Data Set', 'tgt_id': 'Assertions', 'weight': 8.0, 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'keywords': 'evaluation target, data scope', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertions', 'Primary Metric'): [{'src_id': 'Primary Metric', 'tgt_id': 'Assertions', 'weight': 9.0, 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'keywords': 'evaluation criteria, measurement target', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertions', 'Clinical Entities'): [{'src_id': 'Assertions', 'tgt_id': 'Clinical Entities', 'weight': 7.0, 'description': 'The overall performance for all three types of clinical entities and all six types of assertions across 477 annotated notes were considered as the primary metric in the challenge.', 'keywords': 'attribute, related concept', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Assertion Classification Tasks', 'Assertions'): [{'src_id': 'Assertion Classification Tasks', 'tgt_id': 'Assertions', 'weight': 8.0, 'description': 'The authors applied the hybrid system to the concept extraction and assertion classification tasks in the challenge and evaluated its performance using a test data set with 477 annotated notes.', 'keywords': 'task target, operation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}], ('Clinical Entities', 'Concept Extraction Tasks'): [{'src_id': 'Concept Extraction Tasks', 'tgt_id': 'Clinical Entities', 'weight': 8.0, 'description': "The authors' goal was to develop and evaluate machine-learning-based approaches to extracting clinical entities-including medical problems, tests, and treatments, as well as their asserted statusd-from hospital discharge summaries written using natural language.", 'keywords': 'task target, operation', 'source_id': 'chunk-f2d0cc67b36a0ae82c45c3a47515eabb', 'file_path': 'example.txt'}]})
