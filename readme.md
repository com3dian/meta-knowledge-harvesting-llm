# README
## Related Works
- 🔍 Knowledge Retrival
- 🏆 Benchmarking
- 🌍 Domain Knowledge (`\cite{GraphRAG}`)
- 🎓 Pretrained

| Paper | Journal/Conference |
|--|--|
| [From Local to Global: A GraphRAG Approach to Query-Focused Summarization](https://arxiv.org/abs/2404.16130) 🔍🏆 | preprint |
| [SCILITLLM: HOW TO ADAPT LLMS FOR SCIENTIFIC LITERATURE UNDERSTANDING](https://arxiv.org/abs/2408.15545) 🔍🏆🎓 | ICLR |
| [SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature](http://arxiv.org/abs/2406.07835) 🏆 | preprint |
| [SCIBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/pdf/1903.10676) 🔍🎓 | EMNLP |
| [Large language models for scientific discovery in molecular property prediction](https://doi.org/10.1038/s42256-025-00994-z) 🌍 | Nature Machine Intelligence |
| [Structured information extraction from scientific text with large language models](https://doi.org/10.1038/s41467-024-45563-x) 🌍 | Nature Communications |
| [Extracting accurate materials data from research papers with conversational language models and prompt engineering](https://doi.org/10.1038/s41467-024-45914-8) 🌍 | Nature Communications |
| [Galactica: A Large Language Model for Science](https://arxiv.org/pdf/2211.09085) 🔍🏆 | preprint |
| [LightRAG: Simple and Fast Retrieval-Augmented Generation](https://arxiv.org/abs/2410.05779) 🔍 | preprint |
| [SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis](http://arxiv.org/abs/2403.01976) 🏆 | preprint |
| [SciKnowEval: Evaluating Multi-level Scientific Knowledge of Large Language Models](http://arxiv.org/abs/2406.09098) 🏆 | preprint |
| [SciRepEval: A Multi-Format Benchmark for Scientific Document Representations](https://aclanthology.org/2023.emnlp-main.338/) 🏆 | EMNLP |
| [KGGen: Extracting Knowledge Graphs from Plain Text with Language Models](https://arxiv.org/abs/2502.09956) | preprint |
| [STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification](https://arxiv.org/abs/2503.06277) | CVPR |
